{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('..')\n",
    "import os\n",
    "import json\n",
    "from time import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.cuda.dnn import dnn_conv\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. The code from the following imports is lifted from the original [dcgan project](https://github.com/Newmu/dcgan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'theano_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c27b1bc22bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrng\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_rng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatchnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_cond_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/classwinter17/stat442/finalproject/ml-image-denoising/lib/updates.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshared0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml2norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'theano_utils'"
     ]
    }
   ],
   "source": [
    "from lib import activations\n",
    "from lib import updates\n",
    "from lib import inits\n",
    "from lib.rng import py_rng, np_rng\n",
    "from lib.ops import batchnorm, conv_cond_concat, deconv, dropout, l2normalize\n",
    "from lib.metrics import nnc_score, nnd_score\n",
    "from lib.theano_utils import floatX, sharedX\n",
    "from lib.data_utils import OneHot, shuffle, iter_data, center_crop, patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "from fuel.schemes import ShuffledScheme, SequentialScheme\n",
    "from fuel.streams import DataStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "try:\n",
    "    hf[\"target\"].shape\n",
    "except:\n",
    "    hf = h5py.File('faces.hdf5','r+')\n",
    "num_samples = hf[\"input\"].shape[0]\n",
    "\n",
    "print \"number of samples in dataset : %i\" %num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "     'train': {'input': (2000, num_samples), 'target': (2000, num_samples)},\n",
    "     'test': {'input': (0, 1000), 'target': (0, 1000)},\n",
    "     'val': {'input': (1000, 2000), 'target': (1000, 2000)}\n",
    "}\n",
    "\n",
    "hf.attrs['split'] = H5PYDataset.create_split_array(split_dict)\n",
    "train_set = H5PYDataset('faces.hdf5', which_sets=('train',))\n",
    "test_set = H5PYDataset('faces.hdf5', which_sets=('test',))\n",
    "val_set = H5PYDataset('faces.hdf5', which_sets=('val',))\n",
    "\n",
    "#batch_size = 128\n",
    "batch_size = 12\n",
    "#TODO : use shuffledscheme instead?  Seems slower, might have screwed up the chunksize in the HDF5 files?\n",
    "\n",
    "tr_scheme = SequentialScheme(examples=train_set.num_examples, batch_size=batch_size)\n",
    "tr_stream = DataStream(train_set, iteration_scheme=tr_scheme)\n",
    "\n",
    "val_scheme = SequentialScheme(examples=val_set.num_examples, batch_size=batch_size)\n",
    "val_stream = DataStream(val_set, iteration_scheme=val_scheme)\n",
    "\n",
    "test_scheme = SequentialScheme(examples=test_set.num_examples, batch_size=batch_size)\n",
    "test_stream = DataStream(test_set, iteration_scheme=test_scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data looks sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x_train, x_target in tr_stream.get_epoch_iterator():\n",
    "    break\n",
    "print \"EXAMPLE TARGET IMAGE:\"\n",
    "\n",
    "Image.fromarray(x_target[3].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"EXAMPLE INPUT IMAGE:\"\n",
    "Image.fromarray(x_train[3].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_transform(X):\n",
    "    return floatX(X).transpose(0, 3, 1, 2)/127.5 - 1.\n",
    "\n",
    "def input_transform(X):\n",
    "    return target_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2 = 1e-5         # l2 weight decay\n",
    "nvis = 196        # # of samples to visualize during training\n",
    "b1 = 0.5          # momentum term of adam\n",
    "nc = 3            # # of channels in image\n",
    "#nbatch = 128      # # of examples in batch\n",
    "nbatch = 12      # # of examples in batch\n",
    "npx = 64          # # of pixels width/height of images\n",
    "\n",
    "nx = npx*npx*nc   # # of dimensions in X\n",
    "niter = 1000        # # of iter at starting learning rate\n",
    "niter_decay = 30   # # of iter to linearly decay learning rate to zero\n",
    "lr = 0.0002       # initial learning rate for adam\n",
    "ntrain = 25000   # # of examples to train on\n",
    "\n",
    "relu = activations.Rectify()\n",
    "sigmoid = activations.Sigmoid()\n",
    "lrelu = activations.LeakyRectify()\n",
    "tanh = activations.Tanh()\n",
    "bce = T.nnet.binary_crossentropy\n",
    "\n",
    "def mse(x,y):\n",
    "    return T.sum(T.pow(x-y,2), axis = 1)\n",
    "\n",
    "gifn = inits.Normal(scale=0.02)\n",
    "difn = inits.Normal(scale=0.02)\n",
    "sigma_ifn = inits.Normal(loc = -100., scale=0.02)\n",
    "gain_ifn = inits.Normal(loc=1., scale=0.02)\n",
    "bias_ifn = inits.Constant(c=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following methods are to help adjust the sizes of the convolutional layers in the generator and discriminator, which is very fiddly to do otherwise.  The (overloaded) method make_conv_set can be used to create both the conv \n",
    "and deconv sets of layers.  Note that the 'size' of the images is the size of the shortest side (32 in the input set, 128 in the target set).  Only use powers of 2 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_conv_layer(X, input_size, output_size, input_filters, \n",
    "                    output_filters, name, index,\n",
    "                    weights = None, filter_sz = 5):\n",
    "    \n",
    "    is_deconv = output_size >= input_size\n",
    "\n",
    "    w_size = (input_filters, output_filters, filter_sz, filter_sz) \\\n",
    "            if is_deconv else (output_filters, input_filters, filter_sz, filter_sz)\n",
    "    \n",
    "    if weights is None:\n",
    "        w = gifn(w_size, '%sw%i' %(name, index))\n",
    "        g = gain_ifn((output_filters), '%sg%i' %(name, index))\n",
    "        b = bias_ifn((output_filters), '%sb%i' %(name, index))\n",
    "    else:\n",
    "        w,g,b = weights\n",
    "        \n",
    "    \n",
    "    conv_method = deconv if is_deconv else dnn_conv\n",
    "    activation = relu if is_deconv else lrelu\n",
    "    \n",
    "    sub = output_size / input_size if is_deconv else input_size / output_size\n",
    "    \n",
    "    if filter_sz == 3:\n",
    "        bm = 1\n",
    "    else:\n",
    "        bm = 2\n",
    "    \n",
    "    layer = activation(batchnorm(conv_method(X, w, subsample=(sub, sub), border_mode=(bm, bm)), g=g, b=b))\n",
    "    \n",
    "    return layer, [w,g,b]\n",
    "\n",
    "def make_conv_set(input, layer_sizes, num_filters, name, weights = None, filter_szs = None):\n",
    "    assert(len(layer_sizes) == len(num_filters))\n",
    "    \n",
    "    vars_ = []\n",
    "    layers_ = []\n",
    "    current_layer = input\n",
    "    \n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        input_size = layer_sizes[i]\n",
    "        output_size = layer_sizes[i + 1]\n",
    "        input_filters = num_filters[i]\n",
    "        output_filters = num_filters[i + 1]\n",
    "        \n",
    "        if weights is not None:\n",
    "            this_wts = weights[i * 3 : i * 3 + 3]\n",
    "        else:\n",
    "            this_wts = None\n",
    "            \n",
    "        if filter_szs != None:\n",
    "            filter_sz = filter_szs[i]\n",
    "        else:\n",
    "            filter_sz = 5\n",
    "        \n",
    "        layer, new_vars = make_conv_layer(current_layer, input_size, output_size, \n",
    "                                          input_filters, output_filters, name, i, \n",
    "                                          weights = this_wts, filter_sz = filter_sz)\n",
    "        \n",
    "        vars_ += new_vars\n",
    "        layers_ += [layer]\n",
    "        current_layer = layer\n",
    "        \n",
    "    return current_layer, vars_, layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Use code below if you want use a saved model\n",
    "'''\n",
    "[e_params, g_params, d_params] = pickle.load( open( \"models/autoencoder_100epoch/faces_dcgan_denoising_64epoch_100encoding.pkl\", \"rb\" ) )\n",
    "gwx = g_params[-1]\n",
    "dwy = d_params[-1]\n",
    "\n",
    "# inputs\n",
    "X = T.tensor4()\n",
    "\n",
    "## encode layer\n",
    "e_layer_sizes = [128, 64, 32, 16, 8]\n",
    "e_filter_sizes = [3, 256, 256, 512, 1024]\n",
    "\n",
    "eX, e_params, e_layers = make_conv_set(X, e_layer_sizes, e_filter_sizes, \"e\", weights=e_params)\n",
    "\n",
    "## generative layer\n",
    "g_layer_sizes = [8, 16, 32, 64, 128]\n",
    "g_num_filters = [1024, 512, 256, 256, 128]\n",
    "\n",
    "\n",
    "g_out, g_params, g_layers = make_conv_set(eX, g_layer_sizes, g_num_filters, \"g\", weights=g_params)\n",
    "g_params += [gwx]\n",
    "gX = tanh(deconv(g_out, gwx, subsample=(1, 1), border_mode=(2, 2)))\n",
    "\n",
    "\n",
    "## discrim layer(s)\n",
    "\n",
    "df1 = 128\n",
    "d_layer_sizes = [128, 64, 32, 16, 8]\n",
    "d_filter_sizes = [3, df1, 2 * df1, 4 * df1, 8 * df1]\n",
    "\n",
    "def discrim(input, name, weights=None):\n",
    "    d_out, disc_params, d_layers = make_conv_set(input, d_layer_sizes, d_filter_sizes, name, weights = weights)\n",
    "    d_flat = T.flatten(d_out, 2)\n",
    "    \n",
    "    disc_params += [dwy]\n",
    "    y = sigmoid(T.dot(d_flat, dwy))\n",
    "    \n",
    "    return y, disc_params, d_layers\n",
    "\n",
    "# target outputs\n",
    "target = T.tensor4()\n",
    "\n",
    "p_real, d_params, d_layers = discrim(target, \"d\", weights=d_params)\n",
    "#we need to make sure the p_gen params are the same as the p_real params\n",
    "p_gen , d_params2, d_layers = discrim(gX, \"d\", weights=d_params)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#Use code below if you are training a model from scratch\n",
    "\n",
    "# inputs\n",
    "X = T.tensor4()\n",
    "\n",
    "## encode layer\n",
    "e_layer_sizes = [128, 64, 32, 16, 8]\n",
    "e_filter_sizes = [3, 256, 256, 512, 1024]\n",
    "\n",
    "eX, e_params, e_layers = make_conv_set(X, e_layer_sizes, e_filter_sizes, \"e\")\n",
    "\n",
    "## generative layer\n",
    "g_layer_sizes = [8, 16, 32, 64, 128]\n",
    "g_num_filters = [1024, 512, 256, 256, 128]\n",
    "\n",
    "\n",
    "g_out, g_params, g_layers = make_conv_set(eX, g_layer_sizes, g_num_filters, \"g\")\n",
    "gwx = gifn((128, nc, 5, 5), 'gwx')\n",
    "g_params += [gwx]\n",
    "gX = tanh(deconv(g_out, gwx, subsample=(1, 1), border_mode=(2, 2)))\n",
    "\n",
    "\n",
    "## discrim layer(s)\n",
    "\n",
    "df1 = 128\n",
    "d_layer_sizes = [128, 64, 32, 16, 8]\n",
    "d_filter_sizes = [3, df1, 2 * df1, 4 * df1, 8 * df1]\n",
    "\n",
    "dwy = difn((df1 * 8 * 10 * 8, 1), 'dwy')\n",
    "\n",
    "def discrim(input, name, weights=None):\n",
    "    d_out, disc_params, d_layers = make_conv_set(input, d_layer_sizes, d_filter_sizes, name, weights = weights)\n",
    "    d_flat = T.flatten(d_out, 2)\n",
    "    \n",
    "    disc_params += [dwy]\n",
    "    y = sigmoid(T.dot(d_flat, dwy))\n",
    "    \n",
    "    return y, disc_params, d_layers\n",
    "\n",
    "# target outputs\n",
    "target = T.tensor4()\n",
    "\n",
    "p_real, d_params, d_layers = discrim(target, \"d\")\n",
    "#we need to make sure the p_gen params are the same as the p_real params\n",
    "p_gen , d_params2, d_layers = discrim(gX, \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test everything working so far (errors are most likely size mismatches)\n",
    "f = theano.function([X], p_gen)\n",
    "f(input_transform(x_train)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up the various cost functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "\n",
    "## GAN costs\n",
    "d_cost_real = bce(p_real, T.ones(p_real.shape)).mean()\n",
    "d_cost_gen = bce(p_gen, T.zeros(p_gen.shape)).mean()\n",
    "g_cost_d = bce(p_gen, T.ones(p_gen.shape)).mean()\n",
    "\n",
    "## MSE encoding cost is done on an (averaged) downscaling of the image\n",
    "target_pool = max_pool_2d(target, (4,4), mode=\"average_exc_pad\",ignore_border=True)\n",
    "target_flat = T.flatten(target_pool, 2)\n",
    "gX_pool = max_pool_2d(gX, (4,4), mode=\"average_exc_pad\",ignore_border=True)\n",
    "gX_flat = T.flatten(gX_pool,2)\n",
    "enc_cost = mse(gX_flat, target_flat).mean() \n",
    "\n",
    "## MSE encoding without max pooling\n",
    "'''\n",
    "target_flat = T.flatten(target, 2)\n",
    "gX_flat = T.flatten(gX,2)\n",
    "enc_cost = mse(gX_flat, target_flat).mean() \n",
    "'''\n",
    "\n",
    "## generator cost is a linear combination of the discrim cost plus the MSE enocding cost\n",
    "d_cost = d_cost_real + d_cost_gen\n",
    "\n",
    "#To change the weight of MSE, change the denominator.  ex. enc_cost/5 weights MSE much less that enc_cost/1\n",
    "g_cost = g_cost_d + enc_cost / 1  \n",
    "\n",
    "## N.B. e_cost and e_updates will only try and minimise MSE loss on the autoencoder (for debugging)\n",
    "e_cost = enc_cost\n",
    "\n",
    "cost = [g_cost_d, d_cost_real, enc_cost]\n",
    "\n",
    "elrt = sharedX(0.002)\n",
    "lrt = sharedX(lr)\n",
    "d_updater = updates.Adam(lr=lrt, b1=b1, regularizer=updates.Regularizer(l2=l2))\n",
    "g_updater = updates.Adam(lr=lrt, b1=b1, regularizer=updates.Regularizer(l2=l2))\n",
    "e_updater = updates.Adam(lr=elrt, b1=b1, regularizer=updates.Regularizer(l2=l2))\n",
    "\n",
    "d_updates = d_updater(d_params, d_cost)\n",
    "g_updates = g_updater(e_params + g_params, g_cost)\n",
    "e_updates = e_updater(e_params, e_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'COMPILING'\n",
    "t = time()\n",
    "_train_g = theano.function([X, target], cost, updates=g_updates)\n",
    "_train_d = theano.function([X, target], cost, updates=d_updates)\n",
    "_train_e = theano.function([X, target], cost, updates=e_updates)\n",
    "_get_cost = theano.function([X, target], cost)\n",
    "print '%.2f seconds to compile theano functions'%(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code\n",
    "\n",
    "Code for generating the images every 100 batches or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_dir = \"gen_images/\"\n",
    "\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "ae_encode = theano.function([X, target], [gX, target])\n",
    "\n",
    "def inverse(X):\n",
    "    X_pred = (X.transpose(0, 2, 3, 1) + 1) * 127.5\n",
    "    X_pred = np.rint(X_pred).astype(int)\n",
    "    X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
    "    return X_pred.astype('uint8')\n",
    "\n",
    "\n",
    "def save_sample_pictures():\n",
    "    for te_train, te_target in test_stream.get_epoch_iterator():\n",
    "        break\n",
    "    te_out, te_ta = ae_encode(input_transform(te_train), target_transform(te_target))\n",
    "    te_reshape = inverse(te_out)\n",
    "    te_target_reshape = inverse(te_ta)\n",
    "\n",
    "    new_size = (128 * 6, 160 * 12)\n",
    "    new_im = Image.new('RGB', new_size)\n",
    "    r = np.random.choice(12, 24, replace=True).reshape(2,12)\n",
    "    for i in range(2):\n",
    "        for j in range(12):\n",
    "            index =  r[i][j]\n",
    "            \n",
    "            target_im = Image.fromarray(te_target_reshape[index])\n",
    "            train_im = Image.fromarray(te_train[index].astype(np.uint8))\n",
    "            im = Image.fromarray(te_reshape[index])\n",
    "            \n",
    "            new_im.paste(target_im, (128 * i * 3, 160 * j))\n",
    "            new_im.paste(train_im, (128 * (i * 3 + 1), 160 * j))\n",
    "            new_im.paste(im, (128 * (i * 3 + 2), 160 * j))\n",
    "    img_loc = \"gen_images/%i.png\" %int(time())     \n",
    "    print \"saving images to %s\" %img_loc\n",
    "    new_im.save(img_loc)\n",
    "\n",
    "#saves output for all testing images.  This may take a couple of minutes to run.\n",
    "def save_all_pictures():\n",
    "    counter = 0\n",
    "    for te_train, te_target in test_stream.get_epoch_iterator():\n",
    "        te_out, te_ta = ae_encode(input_transform(te_train), target_transform(te_target))\n",
    "        te_reshape = inverse(te_out)\n",
    "        te_target_reshape = inverse(te_ta)\n",
    "\n",
    "        new_size = (128 * 3, 160 * 12)\n",
    "        new_im = Image.new('RGB', new_size)\n",
    "        r = [range(12),range(12)]\n",
    "        for i in range(1):\n",
    "            for j in range(12):\n",
    "                index =  r[i][j]\n",
    "                try:\n",
    "                    target_im = Image.fromarray(te_target_reshape[index])\n",
    "                    train_im = Image.fromarray(te_train[index].astype(np.uint8))\n",
    "                    im = Image.fromarray(te_reshape[index])\n",
    "\n",
    "                    new_im.paste(target_im, (128 * i * 3, 160 * j))\n",
    "                    new_im.paste(train_im, (128 * (i * 3 + 1), 160 * j))\n",
    "                    new_im.paste(im, (128 * (i * 3 + 2), 160 * j))\n",
    "                except:\n",
    "                    print \"Eror with training image\"\n",
    "        img_loc = \"gen_images/test_result_%i.png\" %counter     \n",
    "        print \"saving images to %s\" %img_loc\n",
    "        new_im.save(img_loc)\n",
    "        counter+=1\n",
    "\n",
    "#save_all_pictures()        \n",
    "save_sample_pictures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mn(l):\n",
    "    if sum(l) == 0:\n",
    "        return 0\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "## TODO : nicer way of coding these means?\n",
    "\n",
    "def get_test_errors():\n",
    "    print \"getting test error\"\n",
    "    g_costs = []\n",
    "    d_costs = []\n",
    "    e_costs = []\n",
    "    k_costs = []\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            x_train, x_target  = te_iterator.next()\n",
    "        except:\n",
    "            te_iterator = val_stream.get_epoch_iterator()\n",
    "            x_train, x_target  = te_iterator.next()\n",
    "        x = input_transform(x_train)\n",
    "        t = target_transform(x_target)\n",
    "        cost = _get_cost(x,t)\n",
    "        g_cost, d_cost, enc_cost = cost\n",
    "        g_costs.append(g_cost)\n",
    "        d_costs.append(d_cost)\n",
    "        e_costs.append(enc_cost)\n",
    "        \n",
    "    s= \" ,\".join([\"test errors :\", str(mn(g_costs)), str(mn(d_costs)), str(mn(e_costs))])\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Finally, we come to the actual training of the model.  This code can be keyboard interrupted, and the weights will be stored in memory, allowing us to stop, adjust and restart the training (this is how I got the model to train).  For advice on training see the blog post at (#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = tr_stream.get_epoch_iterator()\n",
    "\n",
    "# you may wish to reset the learning rate to something of your choosing if you feel it is too high/low\n",
    "lrt = sharedX(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "n_updates = 0\n",
    "t = time()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "print \"STARTING\"\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    \n",
    "    tm = time()\n",
    "\n",
    "    g_costs = []\n",
    "    d_costs = []\n",
    "    e_costs = []\n",
    "    \n",
    "    ## TODO : produces pretty ugly output, redo this?\n",
    "    for i in tqdm(range(num_samples/128)):\n",
    "        \n",
    "        try:\n",
    "            x_train, x_target  = iterator.next()\n",
    "        except:\n",
    "            iterator = tr_stream.get_epoch_iterator()\n",
    "            x_train, x_target  = iterator.next()\n",
    "        x = input_transform(x_train)\n",
    "        t = target_transform(x_target)\n",
    "\n",
    "        \n",
    "        ## optional - change the criteria for how often we train the generator or discriminator\n",
    "        if n_updates % 2 == 1:\n",
    "            cost = _train_g(x,t) \n",
    "        else:\n",
    "            cost = _train_d(x,t)\n",
    "            \n",
    "        # optional - only train the generator on MSE cost.  If you want to only train the autoencoder, uncomment the\n",
    "        #            and comment the cost updates above\n",
    "        #cost = _train_e(x,t)\n",
    "        g_cost, d_cost, enc_cost = cost\n",
    "        g_costs.append(g_cost)\n",
    "        d_costs.append(d_cost)\n",
    "        e_costs.append(enc_cost)\n",
    "\n",
    "        if n_updates % 100 == 0:\n",
    "            s= \" ,\".join([\"training errors :\", str(mn(g_costs)), str(mn(d_costs)), str(mn(e_costs))])\n",
    "            g_costs = []\n",
    "            d_costs = []\n",
    "            e_costs = []\n",
    "            print get_test_errors()\n",
    "            print s\n",
    "            sys.stdout.flush()\n",
    "            save_sample_pictures()\n",
    "        n_updates += 1  \n",
    "\n",
    "    print \"epoch %i of %i took %.2f seconds\" %(epoch, n_epochs, time() - tm)\n",
    "    \n",
    "    ## optional - reduce the learning rate as you go\n",
    "    #lrt.set_value(floatX(lrt.get_value() * 0.95))\n",
    "    #print lrt.get_value()\n",
    "    \n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights if wanted\n",
    "You can reuse them by using the weights in the make_conv_set method #TODO - actually try this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "all_params = [e_params, g_params, d_params]\n",
    "\n",
    "pickle.dump(all_params, open(\"faces_dcgan_denoising_165epoch_1encoding.pkl\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
